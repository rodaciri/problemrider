---
title: Excessive Logging
description: Applications generate a very high volume of logs, consuming excessive
  disk space and potentially impacting performance.
category:
- Code
- Performance
related_problems:
- slug: log-spam
  similarity: 0.65
- slug: lazy-loading
  similarity: 0.65
- slug: excessive-disk-io
  similarity: 0.6
- slug: logging-configuration-issues
  similarity: 0.6
- slug: imperative-data-fetching-logic
  similarity: 0.6
- slug: excessive-object-allocation
  similarity: 0.6
layout: problem
---

## Description
Excessive logging can have a significant impact on application performance and maintainability. When an application logs too much information, it can consume a large amount of disk space, slow down the application, and make it difficult to find important information in the logs. A well-designed logging strategy should be focused on logging only the information that is necessary for debugging and monitoring. This requires a deep understanding of the application and its use cases.


## Indicators ⟡
- Log files are growing at an unexpectedly high rate.
- You are paying a lot of money for log storage and analysis.
- It is difficult to find important information in your logs because of the noise.
- Your application is slow, and you suspect that logging is a contributing factor.


## Symptoms ▲

- [Logging Configuration Issues](logging-configuration-issues.md) <span class="info-tooltip" title="Confidence: 0.464, Strength: 0.695">ⓘ</span>
<br/>  Improperly configured logging mechanisms can lead to an overwhelming amount of log entries, which not only fills disk space quickly but may also obscure essential information and create security risks, thereby serving as a clear indicator of excessive logging issues in legacy systems.
- [Upstream Timeouts](upstream-timeouts.md) <span class="info-tooltip" title="Confidence: 0.398, Strength: 0.590">ⓘ</span>
<br/>  The high volume of logs generated by the application can lead to increased disk I/O and slower processing times, causing delays in response from the API that exceed the configured timeout window for consuming services.
- [Delayed Value Delivery](delayed-value-delivery.md) <span class="info-tooltip" title="Confidence: 0.393, Strength: 0.725">ⓘ</span>
<br/>  The excessive volume of logs consumes disk space and processing resources, leading to slower build and deployment cycles, which in turn delays the delivery of new features and bug fixes to users.
- [Unreleased Resources](unreleased-resources.md) <span class="info-tooltip" title="Confidence: 0.363, Strength: 0.642">ⓘ</span>
<br/>  The generation of excessive logs often leads to unreleased system resources as the high volume of log entries can overwhelm the resource management processes, resulting in allocated resources that remain open and unclosed, thus compounding the performance and storage issues.
- [Interrupt Overhead](interrupt-overhead.md) <span class="info-tooltip" title="Confidence: 0.338, Strength: 0.744">ⓘ</span>
<br/>  The high volume of log generation leads to frequent disk I/O operations, which in turn create excessive hardware interrupts that disrupt the CPU's execution flow and result in increased context switching, ultimately degrading application performance in legacy systems.

## Root Causes ▼

*No significant relationships within the scope of legacy systems identified (yet).*

## Detection Methods ○

- **Disk Usage Monitoring:** Monitor disk space consumption on servers where logs are stored.
- **I/O Monitoring:** Use system monitoring tools to track disk write operations related to logging.
- **Log Volume Analysis:** Use log aggregation tools to analyze the volume of logs generated per application or service.
- **Code Review:** Look for logging statements that are overly verbose or placed in performance-critical sections.
- **Configuration Review:** Check logging configurations to ensure appropriate logging levels are set for different environments.


## Examples
A microservice processes millions of events per day. A developer, while debugging an issue, sets the logging level to `DEBUG` and forgets to revert it before deploying to production. Within hours, the server's disk space is completely consumed by log files, causing the service to crash. In another case, an application logs the entire JSON payload of every incoming API request at an `INFO` level. This leads to massive log files and significant network traffic when these logs are shipped to a centralized logging system, even though only a small part of the payload is relevant for most debugging. While logging is crucial for observability, excessive logging can become a performance and cost burden, requiring a balance between providing enough information and avoiding unnecessary overhead.
