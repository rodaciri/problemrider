#!/usr/bin/env python3
"""
Update problem markdown files with relationship descriptions from CSV.

This script reads relationship descriptions generated by generate_relationship_descriptions.py
and adds them as HTML description lines to existing linked relationships in problem files.
"""

import os
import yaml
import argparse
import csv
import re
from typing import Dict, Set

def parse_problem_file(filepath: str) -> tuple[Dict, str, str]:
    """Parse a problem markdown file and return frontmatter, body, and original content."""
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
    
    if not content.startswith('---'):
        raise ValueError(f"Problem file {filepath} missing YAML frontmatter")
    
    parts = content.split('---', 2)
    if len(parts) != 3:
        raise ValueError(f"Invalid frontmatter format in {filepath}")
    
    frontmatter = yaml.safe_load(parts[1])
    body = parts[2].strip()
    
    return frontmatter, body, content

def title_to_slug(title: str) -> str:
    """Convert a problem title to its expected markdown filename slug."""
    return title.lower().replace(' ', '-').replace('(', '').replace(')', '').replace('/', '-')

def load_relationship_descriptions(descriptions_file: str) -> Dict:
    """Load relationship descriptions from CSV file."""
    problems_data = {}
    total_relationships = 0
    
    try:
        with open(descriptions_file, 'r', encoding='utf-8', newline='') as f:
            reader = csv.DictReader(f)
            for row in reader:
                problem_key = row['problem_key']
                related_key = row['related_key']
                relationship_type = row['relationship_type']
                
                # Initialize problem entry if it doesn't exist
                if problem_key not in problems_data:
                    problems_data[problem_key] = {
                        "title": row['problem_title'],
                        "symptoms": {},
                        "root_causes": {}
                    }
                
                # Add relationship
                section = "symptoms" if relationship_type == "symptom" else "root_causes"
                problems_data[problem_key][section][related_key] = {
                    "title": row['related_title'],
                    "description": row['description']
                }
                total_relationships += 1
        
        return {
            "problems": problems_data,
            "metadata": {
                "total_relationships": total_relationships,
                "total_problems": len(problems_data)
            }
        }
    except (FileNotFoundError, csv.Error):
        return {"problems": {}, "metadata": {"total_relationships": 0, "total_problems": 0}}

def add_descriptions_to_section(section_content: str, problem_key: str, section_type: str, descriptions: Dict) -> str:
    """Add descriptions to existing linked relationships in a section."""
    if not descriptions or not descriptions.get("problems"):
        return section_content
    
    problems_data = descriptions.get("problems", {})
    problem_data = problems_data.get(problem_key, {})
    relationships_dict = problem_data.get(section_type, {})
    
    if not relationships_dict:
        return section_content
    
    lines = section_content.split('\n')
    new_lines = []
    i = 0
    
    while i < len(lines):
        line = lines[i]
        
        # Check if this line contains a markdown link with tooltip
        link_match = re.search(r'\[([^\]]+)\]\(([^)]+)\.md\)', line)
        if link_match and '<span class="info-tooltip"' in line:
            link_text = link_match.group(1)
            link_file = link_match.group(2)
            
            # Check if we have a description for this relationship
            if link_file in relationships_dict:
                description = relationships_dict[link_file].get("description", "")
                if description:
                    new_lines.append(line)
                    # Check if next line is already a description line
                    if i + 1 < len(lines) and lines[i + 1].strip().startswith('<br/>'):
                        # Replace existing description
                        new_lines.append(f"<br/>  {description}")
                        i += 1  # Skip the old description line
                    else:
                        # Add new description line
                        new_lines.append(f"<br/>  {description}")
                else:
                    new_lines.append(line)
            else:
                new_lines.append(line)
        else:
            new_lines.append(line)
        
        i += 1
    
    return '\n'.join(new_lines)

def update_problem_file(filepath: str, descriptions: Dict, dry_run: bool = False) -> bool:
    """Update a single problem file with relationship descriptions."""
    try:
        frontmatter, body, original_content = parse_problem_file(filepath)
        problem_title = frontmatter.get('title', '')
        
        if not problem_title:
            print(f"⚠️  Skipping {filepath}: No title in frontmatter")
            return False
        
        # Get problem key from filepath
        problem_key = os.path.splitext(os.path.basename(filepath))[0]
        
        print(f"📄 Processing: {problem_title}")
        
        # Check if we have descriptions for this problem
        problems_data = descriptions.get("problems", {})
        if problem_key not in problems_data:
            print(f"   ⚠️  No descriptions found for {problem_title}")
            return False
        
        problem_data = problems_data[problem_key]
        symptoms_count = len(problem_data.get("symptoms", {}))
        root_causes_count = len(problem_data.get("root_causes", {}))
        
        print(f"   Found {symptoms_count} symptom descriptions, {root_causes_count} root cause descriptions")
        
        if symptoms_count == 0 and root_causes_count == 0:
            print(f"   ⚠️  No descriptions to add for {problem_title}")
            return False
        
        # Split body into sections
        sections = re.split(r'^## ', body, flags=re.MULTILINE)
        new_body_parts = []
        updated = False
        
        for i, section in enumerate(sections):
            if i == 0:  # First part before any ## header
                new_body_parts.append(section.rstrip())
                continue
            
            section_name = section.split('\n')[0].strip()
            section_content = '\n'.join(section.split('\n')[1:])
            
            # Add descriptions to Symptoms and Root Causes sections
            if section_name.startswith('Symptoms'):
                updated_content = add_descriptions_to_section(section_content, problem_key, "symptoms", descriptions)
                if updated_content != section_content:
                    updated = True
                new_body_parts.append(f"## {section_name}\n{updated_content}")
            elif section_name.startswith('Root Causes'):
                updated_content = add_descriptions_to_section(section_content, problem_key, "root_causes", descriptions)
                if updated_content != section_content:
                    updated = True
                new_body_parts.append(f"## {section_name}\n{updated_content}")
            else:
                # Keep other sections unchanged
                new_body_parts.append(f"## {section}")
        
        if not updated:
            print(f"   ⚠️  No changes needed for {problem_title}")
            return False
        
        # Reconstruct the full file content - preserve original frontmatter format
        original_frontmatter = original_content.split('---')[1]
        new_content = "---" + original_frontmatter + "---\n\n"
        
        # Clean up multiple blank lines and ensure proper spacing between sections
        body_content = '\n'.join(new_body_parts).strip()
        # Remove multiple consecutive blank lines and replace with single blank lines
        body_content = re.sub(r'\n{3,}', '\n\n', body_content)
        # Ensure there's a blank line before each ## heading (except the first one)
        body_content = re.sub(r'([^\n])\n(## )', r'\1\n\n\2', body_content)
        new_content += body_content + '\n'
        
        if dry_run:
            print(f"   🔍 DRY RUN - Would update {filepath}")
            return True
        
        # Write the updated content
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(new_content)
        
        print(f"   ✅ Updated {filepath}")
        return True
        
    except Exception as e:
        print(f"   ❌ Error processing {filepath}: {e}")
        return False

def get_existing_problems(problems_dir: str) -> Set[str]:
    """Get set of existing problem slugs from the problems directory."""
    existing = set()
    for filename in os.listdir(problems_dir):
        if filename.endswith('.md'):
            slug = filename[:-3]  # Remove .md extension
            existing.add(slug)
    return existing

def main():
    parser = argparse.ArgumentParser(
        description="Update problem files with relationship descriptions from CSV",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument('descriptions_file', 
                       help='CSV file containing relationship descriptions')
    parser.add_argument('--problems-dir', default='_problems',
                       help='Directory containing problem markdown files (default: _problems)')
    parser.add_argument('--dry-run', action='store_true',
                       help='Show what would be updated without making changes')
    parser.add_argument('--problem-filter', 
                       help='Only update problems matching this title substring (case insensitive)')
    
    args = parser.parse_args()
    
    print("🚀 Problem Descriptions Update")
    print("=" * 50)
    print(f"📄 Descriptions file: {args.descriptions_file}")
    print(f"📁 Problems dir: {args.problems_dir}")
    if args.dry_run:
        print("🔍 DRY RUN MODE - No files will be modified")
    print()
    
    # Load relationship descriptions
    descriptions = load_relationship_descriptions(args.descriptions_file)
    if descriptions and descriptions.get("problems"):
        metadata = descriptions.get("metadata", {})
        total_relationships = metadata.get("total_relationships", 0)
        total_problems = metadata.get("total_problems", 0)
        print(f"✅ Loaded {total_relationships} relationship descriptions for {total_problems} problems")
    else:
        print(f"❌ No relationship descriptions found in {args.descriptions_file}")
        return 1
    
    # Get existing problems
    if not os.path.exists(args.problems_dir):
        print(f"❌ Problems directory {args.problems_dir} does not exist")
        return 1
    
    existing_problems = get_existing_problems(args.problems_dir)
    print(f"📊 Found {len(existing_problems)} existing problem files")
    print()
    
    # Process each problem file
    problem_files = [f for f in os.listdir(args.problems_dir) if f.endswith('.md')]
    problem_files.sort()
    
    updated_count = 0
    skipped_count = 0
    
    for filename in problem_files:
        filepath = os.path.join(args.problems_dir, filename)
        
        # Apply filter if specified
        if args.problem_filter:
            try:
                frontmatter, _, _ = parse_problem_file(filepath)
                title = frontmatter.get('title', '')
                if args.problem_filter.lower() not in title.lower():
                    continue
            except Exception:
                continue  # Skip files we can't parse
        
        if update_problem_file(filepath, descriptions, args.dry_run):
            updated_count += 1
        else:
            skipped_count += 1
    
    print()
    print("📊 Summary:")
    print(f"   ✅ Files updated: {updated_count}")
    print(f"   ⚠️  Files skipped: {skipped_count}")
    
    if args.dry_run:
        print("\n🔍 This was a dry run. Use without --dry-run to apply changes.")
    
    return 0

if __name__ == '__main__':
    exit(main())